\documentclass[20pt]{article}
%Packages
\usepackage[T1,T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,ukrainian]{babel}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{changepage}
\usepackage{minted}
%\setminted[python]{breaklines}

%Header information
\title{"DeepLearning.AI TensorFlow Developer" Specialization }
\author{ Andrii X }
\date{}

\begin{document}
	\maketitle
	
	\section{Introduction to TensorFlow for AI, ML, and DL}
	\subsection{Week 1}
	\begin{itemize}
		
		\item \textbf{Simple example aka "Hello, World!":}
		\\
		Define NN (1 layer with 1 neuron):
		\begin{minted}{python}
# Build a simple Sequential model
model = tf.keras.Sequential(
[keras.layers.Dense(units=1, input_shape=[1])]
)
		\end{minted}
		Compile the model:
		\begin{minted}{python}
model.compile(optimizer='sgd', loss='mean_squared_error')
		\end{minted}
		Provide the data:
		\begin{minted}{python}
# Declare model inputs and outputs for training
xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)
ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)	
		\end{minted}
		Train the NN:
		\begin{minted}{python}
# Train the model
model.fit(xs, ys, epochs=500)	
		\end{minted}
		Use trained NN for new data:
		\begin{minted}{python}
# Make a prediction
print(model.predict([10.0]))	
		\end{minted}
	\end{itemize}
	\subsection{Week 2}
	\begin{itemize}
		\item \textbf{A Computer Vision Example: Fashion MNIST dataset}
		\\
		The Fashion MNIST dataset is a collection of grayscale 28x28 pixel clothing images.
		\\
		1) Load the Fashion MNIST dataset:
		\begin{minted}{python}
fmnist = tf.keras.datasets.fashion_mnist
		\end{minted}
		2) Load the training and test split of the Fashion MNIST dataset:
		\begin{minted}{python}
(training_images, training_labels), 
(test_images, test_labels) = fmnist.load_data()
		\end{minted}
		3) Normalize the pixel values of the train and test images:
		\begin{minted}{python}
training_images  = training_images / 255.0
test_images = test_images / 255.0
		\end{minted}
		4) Build the classification model:
		\begin{minted}{python}
model = tf.keras.models.Sequential([
tf.keras.layers.Flatten(), 
tf.keras.layers.Dense(128, activation=tf.nn.relu), 
tf.keras.layers.Dense(10, activation=tf.nn.softmax)])
		\end{minted}
		\textbf{Sequential} - defines a sequence of layers in the neural network.\\ \textbf{Flatten} - converts a 28x28 matrix into a 1-D array.\\ \textbf{Dense} - adds a layer of neurons.  
		Activation function \textbf{relu} passes values greater than 0 to the next layer.\\ \textbf{Softmax} takes a list of values and scales these so the sum of all elements will be equal to 1. When applied to model outputs, you can think of the scaled values as the probability for that class.
		\\
		5) Compile and train the model:
		\begin{minted}{python}
model.compile(optimizer = tf.optimizers.Adam(),
loss = 'sparse_categorical_crossentropy',
metrics=['accuracy'])

model.fit(training_images, training_labels, epochs=5)
		\end{minted}
		6) Evaluate the model on unseen data
		\begin{minted}{python}
model.evaluate(test_images, test_labels)
		\end{minted}
		\textit{\underline{Exploration Exercises}}\\
		\textbf{ex1}: the below code c\textbf{reates a set of classifications for each of the test images}, and then prints the first entry in the classifications.
		\begin{minted}{python}
classifications = model.predict(test_images)
print(classifications[0])
# The output of the model is a list of 10 numbers.
# These numbers are a probability that the value
# being classified is the corresponding value
		\end{minted}
		ex2\textbf{}: \textbf{adding more Neurons} we have to do more calculations, slowing down the process, but in this case they have a good impact -- \textbf{we do get more accurate}. That doesn't mean it's always a case of 'more is better', \textbf{you can hit the law of diminishing returns very quickly}!\\
		\textbf{ex3}: it may seem vague right now, but it reinforces \textbf{the rule of thumb that the first layer in your network should be the same shape as your data}. Right now our data is 28x28 images, and 28 layers of 28 neurons would be infeasible, so it makes more sense to 'flatten' that 28,28 into a 784x1.\\
		\textbf{ex4}: \textbf{another rule of thumb} -- the number of neurons in the last layer should match the number of classes you are classifying for.\\
		\textbf{ex5}: consider the effects of additional layers in the network. There isn't a significant impact -- because this is relatively simple data. \textbf{For far more complex data} (including color images to be classified as flowers that you'll see in the next lesson),\textbf{ extra layers are often necessary}.\\
		\textbf{ex6}: consider the \textbf{impact of training for more or less epochs}. Try 15 epochs -- you'll probably get a model with a much better loss than the one with 5. Try 30 epochs -- you might see the loss value decrease more slowly, and sometimes increases. This is a side effect of something called \textbf{'overfitting'}.\\
		\textbf{ex7}: If you try to train the model without normalizing the data, you might find that the model takes longer to train, or that it's unable to learn effectively from the training data, leading to poorer performance on the test data. The reason you get different results with and without normalization is because the scale of the inputs can significantly impact the gradient of the loss function, and hence the updates to the weights during training. \textbf{Normalization ensures that the scale of the inputs is consistent}, which can make the training process more stable and efficient.
		\textbf{ex8}: 'wouldn't it be nice if I could stop the training when I reach a desired value?' -- i.e. 85\% accuracy might be enough for you, and if you reach that after 3 epochs, why sit around waiting for it to finish a lot more epochs.... you have callbacks!
		\begin{minted}{python}
class myCallback(tf.keras.callbacks.Callback):
def on_epoch_end(self, epoch, logs={}):
if logs.get('accuracy') is not None
and logs.get('accuracy') > 0.60:
print("\nReached 60% accuracy so cancelling training!")
self.model.stop_training = True

callbacks = myCallback()

fmnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels) , 
(test_images, test_labels) = fmnist.load_data()

training_images=training_images/255.0
test_images=test_images/255.0
model = tf.keras.models.Sequential([
tf.keras.layers.Flatten(),
tf.keras.layers.Dense(128, activation=tf.nn.relu),
tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])
model.compile(optimizer='adam',
loss='sparse_categorical_crossentropy', metrics=['accuracy'])
# model fitting with callback
model.fit(training_images, training_labels,
epochs=5, callbacks=[callbacks])
		\end{minted}
	\end{itemize}
	\subsection{Week 3: Convolutional NN}
	\begin{itemize}
		\item \textbf{Improving Computer Vision Accuracy using Convolutions}\\
		A neural network containing three layers -- the input layer (in the shape of the data), the output layer (in the shape of the desired output) and only one hidden layer gives accuracy about 89\% on training and 87\% on validation. How does one make that even better? One way is to use something called \textbf{convolutions}. The ultimate \textbf{concept} is that they \textbf{narrow down the content of the image to focus on specific parts} and this will likely improve the model accuracy. This is perfect for computer vision because \textbf{it often highlights features that distinguish one item from another}. Moreover, the \textbf{amount of information needed is then much less} because one will just \textbf{train on the highlighted features}.
		That's the concept of \textbf{Convolutional Neural Networks}.
		\begin{minted}{python}
# Define the model
model = tf.keras.models.Sequential([

# Add convolutions and max pooling
tf.keras.layers.Conv2D(32, (3,3), activation='relu',
input_shape=(28, 28, 1)),
tf.keras.layers.MaxPooling2D(2, 2),
tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
tf.keras.layers.MaxPooling2D(2,2),

# Add the same layers as before
tf.keras.layers.Flatten(),
tf.keras.layers.Dense(128, activation='relu'),
tf.keras.layers.Dense(10, activation='softmax')
])

# Print the model summary
model.summary()

# Use same settings
model.compile(optimizer='adam',
loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
print(f'\nMODEL TRAINING:')
model.fit(training_images, training_labels, epochs=5)

# Evaluate on the test set
print(f'\nMODEL EVALUATION:')
test_loss = model.evaluate(test_images, test_labels)
		\end{minted} 
		\item \textbf{Lab}:
		\begin{minted}{python}
import os
import numpy as np
import tensorflow as tf
from tensorflow import keras

# Load the data
# Get current working directory
current_dir = os.getcwd()
# Append data/mnist.npz to the previous path to get
# the full path
data_path = os.path.join(current_dir, "data/mnist.npz")
# Get only training set
(training_images, training_labels), _ =
tf.keras.datasets.mnist.load_data(path=data_path)
		\end{minted}
		\underline{Pre-processing the data}:\\
		-- Reshape the data so that it has an extra dimension. The reason for this is that commonly you will use 3-dimensional arrays (without counting the batch dimension) to represent image data. The third dimension represents the color using RGB values. This data might be in black and white format so the third dimension doesn't really add any additional information for the classification process but it is a good practice regardless.\\
		-- Normalize the pixel values so that these are values between 0 and 1. You can achieve this by dividing every value in the array by the maximum.
		\begin{minted}{python}
def reshape_and_normalize(images):
### START CODE HERE
# Reshape the images to add an extra dimension
images = images.reshape(images.shape[0],
images.shape[1],
images.shape[2],
1)
# Normalize pixel values
images = images / 255.0
### END CODE HERE
return images

# rest of the code like previously
		\end{minted}
	\end{itemize}
	\subsection{Week 4: Real-life example}
	\begin{itemize}
		\item \textbf{Lab 1: Training with ImageDataGenerator:}\\
		\textbf{Building a Small Model from Scratch}
		\begin{minted}{python}
import tensorflow as tf

model = tf.keras.models.Sequential([
# Note the input shape is the desired size of the 
#image 300x300 with 3 bytes color
# This is the first convolution
tf.keras.layers.Conv2D(16, (3,3), activation='relu',
input_shape=(300, 300, 3)),
tf.keras.layers.MaxPooling2D(2, 2),
# The second convolution
tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
tf.keras.layers.MaxPooling2D(2,2),
# The third convolution
tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
tf.keras.layers.MaxPooling2D(2,2),
# The fourth convolution
tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
tf.keras.layers.MaxPooling2D(2,2),
# The fifth convolution
tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
tf.keras.layers.MaxPooling2D(2,2),
# Flatten the results to feed into a DNN
tf.keras.layers.Flatten(),
# 512 neuron hidden layer
tf.keras.layers.Dense(512, activation='relu'),
# Only 1 output neuron. It will contain a value
# from 0-1 where 0 for 1 class ('horses') and 1 for
# the other ('humans')
tf.keras.layers.Dense(1, activation='sigmoid')
])
		\end{minted}
		The \textbf{increasing number of filters} in deeper layers allows the network to \textbf{capture a hierarchy of features}, from simple to complex, which is essential for the network to understand and classify intricate patterns in images.
		\begin{minted}{python}
from tensorflow.keras.optimizers import RMSprop
	
model.compile(loss='binary_crossentropy',
optimizer=RMSprop(learning_rate=0.001),
metrics=['accuracy'])
		\end{minted}
		In this case, using the \textbf{RMSprop optimization algorithm} is preferable to stochastic gradient descent (SGD), because \textbf{RMSprop automates learning-rate tuning} for us. (Other optimizers, such as Adam and Adagrad, also automatically adapt the learning rate during training, and would work equally well here.)\\
		\textbf{Data Preprocessing}\\
		Next step is to set up the data generators that will read pictures in the source folders, convert them to float32 tensors, and feed them (with their labels) to the model.
		\begin{minted}{python}
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# All images will be rescaled by 1./255
train_datagen = ImageDataGenerator(rescale=1/255)

# Flow training images in batches of 128 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
'./horse-or-human/',  # This is the source directory for training images
target_size=(300, 300),  # All images will be resized to 300x300
batch_size=128,
# Since we use binary_crossentropy loss, we need binary labels
class_mode='binary')
		\end{minted}
		\textbf{Training}\\
		\begin{minted}{python}
history = model.fit(train_generator,
steps_per_epoch=8, epochs=15, verbose=1)
		\end{minted}
		As a result, a \textbf{convnet} processes images by transforming pixels through layers into abstract representations, \textbf{emphasizing key features} and achieving representation sparsity, which refines information about the image's class.
		\item \textbf{Lab 2: ImageDataGenerator with a Validation Set}\\
		\textbf{Building a Small Model from Scratch}
		\begin{minted}{python}
# the same model architecture as before
# in previous lab 1
# the same compile settings as before
		\end{minted}
		\textbf{Data Preprocessing}\\
		It will mostly be the same as last time but notice the additional code to also prepare the validation data.
		\begin{minted}{python}
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# All images will be rescaled by 1./255
train_datagen = ImageDataGenerator(rescale=1/255)
validation_datagen = ImageDataGenerator(rescale=1/255)

# Flow training images in batches of 128 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
'./horse-or-human/',  # This is the source directory for training images
target_size=(300, 300),  # All images will be resized to 300x300
batch_size=128,
# Since you use binary_crossentropy loss, you need binary labels
class_mode='binary')

# Flow validation images in batches of 128 using validation_datagen generator
validation_generator = validation_datagen.flow_from_directory(
'./validation-horse-or-human/',  # This is the source directory for validation images
target_size=(300, 300),  # All images will be resized to 300x300
batch_size=32,
# Since you use binary_crossentropy loss, you need binary labels
class_mode='binary')
		\end{minted}
		\textbf{Training}\\
		Notice that as you train with more epochs, your training accuracy might go up but your validation accuracy goes down. This can be a sign of overfitting and you need to prevent your model from reaching this point.
		\begin{minted}{python}
history = model.fit(
train_generator,
steps_per_epoch=8,  
epochs=15,
verbose=1,
validation_data = validation_generator,
validation_steps=8)
		\end{minted}
	\item \textbf{Final Assignment: Happy or Sad}\\
	The happy or sad dataset, which contains 80 images of emoji-like faces, 40 happy and 40 sad.\\
	The task is to create a convolutional neural network that trains to 99.9\% accuracy on these images, which cancels training upon hitting this training accuracy threshold.
	\begin{minted}{python}
# IMPORTS
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
import os

# LOAD AND EXPLORE THE DATA
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import img_to_array

base_dir = "./data/"
happy_dir = os.path.join(base_dir, "happy/")
sad_dir = os.path.join(base_dir, "sad/")

print("Sample happy image:")
plt.imshow(load_img(f"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}"))
plt.show()

print("\nSample sad image:")
plt.imshow(load_img(f"{os.path.join(sad_dir, os.listdir(sad_dir)[0])}"))
plt.show()

# Load the first example of a happy face
sample_image  = load_img(f"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}")
# Convert the image into its numpy array representation
sample_array = img_to_array(sample_image)
print(f"Each image has shape: {sample_array.shape}")
print(f"The maximum pixel value used is: {np.max(sample_array)}")
	\end{minted}
	\textbf{Defining the callback}\\
	The \textbf{EarlyStopping callback} will monitor the validation loss (val\_loss) by default. If \textbf{the validation loss does not improve} for a specified number of epochs (defined by the patience parameter), \textbf{the training will stop}, and the \textbf{best weights} (from the epoch with the lowest validation loss) \textbf{will be restored} to the model.\\
	Note: To use the EarlyStopping callback effectively, you should have a validation set defined when calling model.fit().
	\begin{minted}{python}
from tensorflow.keras.callbacks import EarlyStopping

# Define the EarlyStopping callback
early_stopping = EarlyStopping(monitor='val_loss', # or 'val_accuracy' depending
# on what you want to monitor
patience=10, # Number of epochs with no improvement after which training will
# be stopped
verbose=1,
restore_best_weights=True) # Restore model weights from the
# epoch with the best value of the monitored quantity.
# Now, when you fit the model, you can use this callback:
# model.fit(..., callbacks=[early_stopping])

class myCallback(tf.keras.callbacks.Callback):
def on_epoch_end(self, epoch, logs={}):
if logs.get('accuracy') is not None and logs.get('accuracy') > 0.999:
print("\nReached 99.9% accuracy so cancelling training!")
self.model.stop_training = True 
	\end{minted}
	\textbf{Pre-processing the data:}
	\begin{minted}{python}
from tensorflow.keras.preprocessing.image import ImageDataGenerator

def image_generator():
	# Instantiate the ImageDataGenerator class.
	train_datagen = ImageDataGenerator(rescale=1/255.0)
	
	train_generator = train_datagen.flow_from_directory(directory=base_dir,
	target_size=(150, 150),
	batch_size=10,
	class_mode='binary')
	
	return train_generator

gen = image_generator()
	\end{minted}
	\textbf{Creating and training your model:}
	\begin{minted}{python}
from tensorflow.keras import optimizers, losses

def train_happy_sad_model(train_generator):

	# Instantiate the callback
	callbacks = myCallback()
	
	# Define the model
	model = tf.keras.models.Sequential([
	# This is the first convolution
	tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),
	tf.keras.layers.MaxPooling2D(2, 2),
	# The second convolution
	tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
	tf.keras.layers.MaxPooling2D(2,2),
	# The third convolution
	tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
	tf.keras.layers.MaxPooling2D(2,2),
	tf.keras.layers.Flatten(),
	tf.keras.layers.Dense(256, activation = 'relu'),
	tf.keras.layers.Dense(1, activation = 'sigmoid')
	])
	
	# Compile the model
	model.compile(loss='binary_crossentropy',
		optimizer=optimizers.RMSprop(learning_rate=0.001),
		metrics=['accuracy'])     
		
	# Train the model
	history = model.fit(x=train_generator,
	epochs=20,
	callbacks=[callbacks]
	)
	
	return history
	
hist = train_happy_sad_model(gen)
	\end{minted}
	*\textbf{Congratulations on finishing} the last assignment of this course!
	\end{itemize}
	
		
	%\begin{minted}{python}
	%	
	%\end{minted}
\end{document}